# ğŸ“„ AskMyPaper â€“ AI-Powered Research Assistant (Offline)

**AskMyPaper** is a local, privacy-first research paper assistant that lets you upload a PDF and ask natural language questions like:  
â¡ï¸ â€œWhat is the main contribution?â€  
â¡ï¸ â€œSummarize section 3.1â€  

Built entirely using local models â€” no API keys or internet needed.

---

## ğŸš€ Features

- ğŸ“„ Upload academic PDF papers
- ğŸ§© Splits and embeds content into semantic chunks
- ğŸ” Retrieves top-k relevant chunks using FAISS
- ğŸ§  Generates answers using **Mistral (7B)** via **Ollama**
- ğŸ§ª Fully offline & fast â€” built with Streamlit

---

## ğŸ“¸ Demo

![AskMyPaper Demo](demo/demo.gif)


---

## âš™ï¸ How It Works

1. PDF is cleaned and text is extracted using PyMuPDF
2. Text is split into overlapping chunks
3. `multi-qa-MiniLM-L6-cos-v1` from `sentence-transformers` generates semantic embeddings
4. FAISS indexes the chunks for retrieval
5. You ask a question â€” top-k chunks are retrieved
6. Answer is generated by Mistral (local) via Ollama

---

## ğŸ§ª Tech Stack

| Component        | Tool/Library                     |
|------------------|----------------------------------|
| LLM              | [Mistral via Ollama](https://ollama.com)
| Embeddings       | `sentence-transformers` (MiniLM)
| Vector Search    | FAISS
| PDF Parsing      | PyMuPDF
| UI Framework     | Streamlit
| OS Tested        | macOS (M4)

---

## ğŸ› ï¸ Local Setup

```bash
# Clone the repository
git clone https://github.com/Aumkarsd/askmypaper.git
cd askmypaper

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install Python dependencies
pip install -r requirements.txt

# Start Ollama server in background (first run downloads model)
ollama run mistral

# Run the Streamlit app
streamlit run app.py

```

## ğŸ’¡ Example Prompts

- Who are the contributors of this paper?
- What are the results mentioned?
- Summarize the abstract in simple terms.
- What is the main contribution of section 2?
- What model or dataset did they use?


## ğŸ“Œ Future Enhancements (Planned)

- [ ] Gemini or OpenAI fallback option
- [ ] Section-aware chunking
- [ ] PDF export of Q&A
- [ ] Follow-up/fine-tuned Q&A interface


## ğŸ‘¤ Author

Built by **[Aumkar Devdhar](https://github.com/Aumkarsd)**  
Graduate from IIT Roorkee   
Passionate about AI, LLMs, and practical ML apps
